{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arnaudpetit/Documents/Programmation/MIT/arnaud/utils/pipeline/cdc_wonder_2018.py:34: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "/Users/arnaudpetit/Documents/Programmation/MIT/arnaud/utils/pipeline/cdc_wonder_2018.py:34: FutureWarning: The default value of regex will change from True to False in a future version.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>cirdeaths</th>\n",
       "      <th>date</th>\n",
       "      <th>resdeaths</th>\n",
       "      <th>totaldeaths</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th>time</th>\n",
       "      <th>category</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">AK</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2018-01-06</th>\n",
       "      <th>65+</th>\n",
       "      <td>11.0</td>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2018-01-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2018-01-13</th>\n",
       "      <th>65+</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2018-01-13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>20.0</td>\n",
       "      <td>2018-01-13</td>\n",
       "      <td>12.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-20</th>\n",
       "      <th>65+</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2018-01-20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">WY</th>\n",
       "      <th>2022-05-07</th>\n",
       "      <th>all</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2022-05-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2022-05-14</th>\n",
       "      <th>65+</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2022-05-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2022-05-14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2022-05-21</th>\n",
       "      <th>65+</th>\n",
       "      <td>13.0</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>all</th>\n",
       "      <td>18.0</td>\n",
       "      <td>2022-05-21</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>23344 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           cirdeaths       date  resdeaths  totaldeaths\n",
       "state time       category                                              \n",
       "AK    2018-01-06 65+            11.0 2018-01-06        0.0         11.0\n",
       "                 all            15.0 2018-01-06        0.0         15.0\n",
       "      2018-01-13 65+            16.0 2018-01-13        0.0         16.0\n",
       "                 all            20.0 2018-01-13       12.0         32.0\n",
       "      2018-01-20 65+            18.0 2018-01-20        0.0         18.0\n",
       "...                              ...        ...        ...          ...\n",
       "WY    2022-05-07 all            15.0 2022-05-07        0.0         15.0\n",
       "      2022-05-14 65+            15.0 2022-05-14        0.0         15.0\n",
       "                 all            15.0 2022-05-14        0.0         15.0\n",
       "      2022-05-21 65+            13.0 2022-05-21        0.0         13.0\n",
       "                 all            18.0 2022-05-21        0.0         18.0\n",
       "\n",
       "[23344 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import auto_wonder_2018_pipeline\n",
    "\n",
    "df = auto_wonder_2018_pipeline(\n",
    "    observed_outcome=[\n",
    "        \"Diseases of the circulatory system\",\n",
    "        \"Diseases of the respiratory system\",\n",
    "    ],\n",
    "    short_outcome=[\"circulatory system\", \"respiratory system\"],\n",
    ")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Timestamp('2019-01-06 00:00:00'), Timestamp('2021-05-21 00:00:00'))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.date.min()+ pd.offsets.DateOffset(years=1), df.date.max()- pd.offsets.DateOffset(years=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from countries_code import code\n",
    "import pandas as pd\n",
    "\n",
    "data_ = pd.read_excel(\"data/ml.xlsx\", sheet_name=None)\n",
    "\n",
    "key_mapper = {\n",
    "    \"FEMA - Major Disaster - Fire\": \"fire\",\n",
    "    \"FEMA - Major Disaster - Earthqu\": \"earthquake\",\n",
    "    \"FEMA - Major Disaster - Hurrica\": \"hurricane\",\n",
    "    \"FEMA - Major Disaster - Tornado\": \"tornado\",\n",
    "    \"FEMA - Major Disaster - Flood\": \"flood\",\n",
    "}\n",
    "data_ = {key_mapper.get(old_key, old_key): value for old_key, value in data_.items()}\n",
    "\n",
    "df_disaster = data_[\"fire\"].loc[:, [\"State\", \"Declaration Date\", \"Incident Type\"]]\n",
    "\n",
    "df_disaster[\"State\"] = df_disaster[\"State\"].map(code)\n",
    "df_disaster = df_disaster.dropna()\n",
    "df_disaster = df_disaster[\n",
    "    (df_disaster[\"Declaration Date\"] >= df.date.min() + pd.offsets.DateOffset(years=1))\n",
    "    & (\n",
    "        df_disaster[\"Declaration Date\"]\n",
    "        <= df.date.max() - pd.offsets.DateOffset(years=1)\n",
    "    )\n",
    "]\n",
    "\n",
    "\n",
    "len(df_disaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import process_data_rd, filter\n",
    "\n",
    "\n",
    "df_temporel = {\n",
    "    (date, state): {\n",
    "        category: process_data_rd(\n",
    "            df.loc[(slice(None), slice(None), category)],\n",
    "            state=state,\n",
    "            disaster_date=date,\n",
    "        )\n",
    "        for category in df.index.unique(level=\"category\")\n",
    "    }\n",
    "    for date, state in zip(df_disaster[\"Declaration Date\"], df_disaster[\"State\"])\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/arnaudpetit/Documents/Programmation/MIT/arnaud/analysis.ipynb Cell 4'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/arnaud/analysis.ipynb#ch0000027?line=15'>16</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m d\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/arnaud/analysis.ipynb#ch0000027?line=18'>19</a>\u001b[0m converter_ \u001b[39m=\u001b[39m \u001b[39mlambda\u001b[39;00m dict_: (\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/arnaud/analysis.ipynb#ch0000027?line=19'>20</a>\u001b[0m     np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39m(dict_\u001b[39m.\u001b[39mkeys())),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/arnaud/analysis.ipynb#ch0000027?line=20'>21</a>\u001b[0m     np\u001b[39m.\u001b[39marray(\u001b[39mlist\u001b[39m(dict_\u001b[39m.\u001b[39mvalues())),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/arnaud/analysis.ipynb#ch0000027?line=21'>22</a>\u001b[0m )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/arnaud/analysis.ipynb#ch0000027?line=23'>24</a>\u001b[0m test \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(df_temporel\u001b[39m.\u001b[39;49mvalues())[\u001b[39m8\u001b[39;49m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/arnaud/analysis.ipynb#ch0000027?line=24'>25</a>\u001b[0m x \u001b[39m=\u001b[39m test\u001b[39m.\u001b[39mcirdeaths\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arnaudpetit/Documents/Programmation/MIT/arnaud/analysis.ipynb#ch0000027?line=27'>28</a>\u001b[0m x_post \u001b[39m=\u001b[39m x[(x\u001b[39m.\u001b[39mindex \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m&\u001b[39m (x\u001b[39m.\u001b[39mindex \u001b[39m<\u001b[39m \u001b[39m12\u001b[39m \u001b[39m*\u001b[39m \u001b[39m30\u001b[39m)]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from typing import List\n",
    "\n",
    "\n",
    "def hist(sx: List[float]):\n",
    "    \"\"\"\n",
    "    Histogram from list of samples\n",
    "    \"\"\"\n",
    "\n",
    "    d = dict()\n",
    "    for s in sx:\n",
    "        d[s] = d.get(s, 0) + 1\n",
    "    return d\n",
    "\n",
    "\n",
    "converter_ = lambda dict_: (\n",
    "    np.array(list(dict_.keys())),\n",
    "    np.array(list(dict_.values())),\n",
    ")\n",
    "\n",
    "test = list(df_temporel.values())[8]\n",
    "x = test.cirdeaths.astype(int)\n",
    "\n",
    "\n",
    "x_post = x[(x.index > 0) & (x.index < 12 * 30)]\n",
    "x_prior = x[(x.index < 0) & (x.index > -12 * 30)]\n",
    "\n",
    "x_ = {\"prior\": x_prior, \"post\": x_post}\n",
    "hist_ = {k: converter_(hist(v)) for k, v in x_.items()}\n",
    "\n",
    "fit_ = {key: sm.NegativeBinomial(*v).fit() for key, v in hist_.items()}\n",
    "\n",
    "statistics__ = lambda mu, lambda_: {\n",
    "    \"r\": 1 / lambda_,\n",
    "    \"p\": 1 / (1 + np.exp(mu) * lambda_),\n",
    "}\n",
    "scores_likehood = {k: v.llf for k, v in fit_.items()}\n",
    "parameters_likehood = {k: statistics_(*(v.params)) for k, v in fit_.items()}\n",
    "\n",
    "for key, score in scores_likehood.items():\n",
    "    print(\"Log Likehood estimator {} {}\".format(key, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import kstest\n",
    "kstest(x_prior, lambda x: nbinom.cdf(x, r, p)).pvalue#,kstest(x_post, lambda x: nbinom.pmf(x, r, p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x15b1c5ee0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.stats import nbinom\n",
    "from scipy.stats import kstest\n",
    "\n",
    "# return (p,r) moment estimation\n",
    "statistics_ = lambda mean, var: {\n",
    "    \"r\": mean ** 2 / (var - mean),\n",
    "    \"p\": mean / var,\n",
    "}\n",
    "\n",
    "\n",
    "split_event = lambda df: (\n",
    "    df[(df.index > 0) & (df.index < 12 * 30)],\n",
    "    df[(df.index < 0) & (df.index > -12 * 30)],\n",
    ")\n",
    "\n",
    "n_categories = len(next(iter(df_temporel)))\n",
    "n_events = len(df_temporel)\n",
    "\n",
    "n_lines = n_events*n_categories\n",
    "\n",
    "fig, axs = plt.subplots(n_lines, n_categories, figsize=(20, 100))\n",
    "\n",
    "for index, (meta, df_dict) in enumerate(df_temporel.items()):\n",
    "    time, location = meta\n",
    "    date = str(time).split(\" \")[0]\n",
    "    \n",
    "    for n_category, (category, df_) in enumerate(df_dict.items()):\n",
    "    #df_ = df_dict['65+']\n",
    "        x, y = df_.cirdeaths.astype(int), df_.resdeaths.astype(int)\n",
    "        x_post, x_prior = split_event(x)\n",
    "        y_post, y_prior = split_event(y)\n",
    "        \n",
    "        #law regression\n",
    "        \n",
    "        x_ = {\"prior\": x_prior, \"post\": x_post}\n",
    "        y_ = {\"prior\": y_prior, \"post\": y_post}\n",
    "        moments_x = {key: (data.mean(), data.var()) for key, data in x_.items()}\n",
    "        moments_y = {key: (data.mean(), data.var()) for key, data in y_.items()}\n",
    "        \n",
    "        #fit_ = {key: sm.NegativeBinomial(*v).fit() for key, v in hist_.items()}\n",
    "        parameters_moments_x = {k: statistics_(*v) for k, v in moments_x.items()}\n",
    "        parameters_moments_y = {k: statistics_(*v) for k, v in moments_y.items()}\n",
    "        \n",
    "        r,p = parameters_moments_x[\"prior\"][\"r\"], parameters_moments_x[\"prior\"][\"p\"]\n",
    "        x_plot = np.arange(x_prior.min(), x_prior.max())#nbinom.ppf(0.01, r, p), nbinom.ppf(0.99, r, p))\n",
    "        likehood = x_prior.map(lambda val: nbinom.logpmf(val, r, p)).sum()\n",
    "        p_value = kstest(x_prior, lambda x: nbinom.cdf(x, r, p)).pvalue\n",
    "        #should make a loop\n",
    "        #x\n",
    "        axs[index*n_categories+n_category, 0].plot(\n",
    "            x_plot,\n",
    "            nbinom.pmf(x_plot, r, p),\n",
    "            label=f\"prior_distrib l-{likehood:.1f}/p-{p_value:.1f}\",\n",
    "            color=\"green\",\n",
    "        )\n",
    "        \n",
    "        r,p = parameters_moments_x[\"post\"][\"r\"], parameters_moments_x[\"post\"][\"p\"]\n",
    "        x_plot = np.arange(x_post.min(), x_post.max())#nbinom.ppf(0.01, r, p), nbinom.ppf(0.99, r, p))\n",
    "        likehood = x_post.map(lambda val: nbinom.logpmf(val, r, p)).sum()\n",
    "        p_value = kstest(x_post, lambda x: nbinom.cdf(x, r, p)).pvalue\n",
    "        \n",
    "        axs[index*n_categories+n_category, 0].plot(\n",
    "            x_plot,\n",
    "            nbinom.pmf(x_plot, r, p),\n",
    "            label=f\"post_distrib l-{likehood:.1f}/p-{p_value:.1f}\",\n",
    "            color=\"red\",\n",
    "        )\n",
    "        \n",
    "        #y\n",
    "        r,p = parameters_moments_y[\"prior\"][\"r\"], parameters_moments_y[\"prior\"][\"p\"]\n",
    "        x_plot = np.arange(y_prior.min(), y_prior.max())#nbinom.ppf(0.01, r, p), nbinom.ppf(0.99, r, p))\n",
    "        likehood = y_prior.map(lambda val: nbinom.logpmf(val, r, p)).sum()\n",
    "        p_value = kstest(y_prior, lambda x: nbinom.cdf(x, r, p)).pvalue\n",
    "        \n",
    "        axs[index*n_categories+n_category, 1].plot(\n",
    "            x_plot,\n",
    "            nbinom.pmf(x_plot, r, p),\n",
    "            label=f\"prior_distrib l-{likehood:.1f}/p-{p_value:.1f}\",\n",
    "            color=\"green\",\n",
    "        )\n",
    "        \n",
    "        r,p = parameters_moments_y[\"post\"][\"r\"], parameters_moments_y[\"post\"][\"p\"]\n",
    "        x_plot = np.arange(y_post.min(), y_post.max())#nbinom.ppf(0.01, r, p), nbinom.ppf(0.99, r, p))\n",
    "        likehood = y_post.map(lambda val: nbinom.logpmf(val, r, p)).sum()\n",
    "        p_value = kstest(y_post, lambda x: nbinom.cdf(x, r, p)).pvalue\n",
    "        \n",
    "        axs[index*n_categories+n_category, 1].plot(\n",
    "            x_plot,\n",
    "            nbinom.pmf(x_plot, r, p),\n",
    "            label=f\"post_distrib l-{likehood:.1f}/p-{p_value:.1f}\",\n",
    "            color=\"red\",\n",
    "        )\n",
    "        \n",
    "        \n",
    "\n",
    "        x_post.hist(ax=axs[index*n_categories+n_category, 0], label=\"post\", density=True)\n",
    "        x_prior.hist(ax=axs[index*n_categories+n_category, 0], alpha=0.8, label=\"prior\", density=True)\n",
    "\n",
    "        y_post.hist(ax=axs[index*n_categories+n_category, 1], label=\"post\", density=True)\n",
    "        y_prior.hist(ax=axs[index*n_categories+n_category, 1],label=\"prior\", alpha=0.8, density=True)\n",
    "         \n",
    "        \n",
    "        axs[index*n_categories+n_category, 0].legend()\n",
    "        axs[index*n_categories+n_category, 0].set_title(f\"{date} in {location}: circulatory diseases {category}\")\n",
    "        axs[index*n_categories+n_category, 1].legend()\n",
    "        axs[index*n_categories+n_category, 1].set_title(f\"respiratory diseases {category}\")\n",
    "    \n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "56faac8612633bcfddb99da3ad5a50bcd343e3e14a61b03833611d8357de7104"
  },
  "kernelspec": {
   "display_name": "R",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
